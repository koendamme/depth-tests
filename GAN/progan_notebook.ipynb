{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 314\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import wandb\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchStd(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniBatchStd, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        std = torch.std(x, dim=1)\n",
    "        mu = std.mean()\n",
    "        rep = mu.repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "\n",
    "        # minibatch_std = torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "\n",
    "        return torch.cat([x, rep], dim=1)\n",
    "\n",
    "\n",
    "class PixelWiseNormalization(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelWiseNormalization, self).__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
    "\n",
    "\n",
    "class WeightedConv2d(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n",
    "        super(WeightedConv2d, self).__init__()\n",
    "\n",
    "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.scale = (2 / (kernel_size**2 * in_channels))**.5\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "\n",
    "        torch.nn.init.normal_(self.conv.weight, mean=0, std=1)\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, apply_pixelnorm=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.apply_pixelnorm = apply_pixelnorm\n",
    "        self.conv1 = WeightedConv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, padding=1)\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(0.2)\n",
    "        self.conv2 = WeightedConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "        self.pixelnorm = PixelWiseNormalization()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.pixelnorm(x) if self.apply_pixelnorm else x\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.pixelnorm(x) if self.apply_pixelnorm else x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_mean_squared_error(fake_batch, real_batch):\n",
    "    nom = torch.linalg.matrix_norm(fake_batch - real_batch[:, None, :, :]) ** 2\n",
    "    denom = torch.linalg.matrix_norm(real_batch) ** 2\n",
    "    o = nom.squeeze()/denom\n",
    "    return o\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Generator, self).__init__()\n",
    "        self.togray_layers = torch.nn.ModuleList([\n",
    "            WeightedConv2d(in_channels=layers[0], out_channels=1, kernel_size=1),\n",
    "            WeightedConv2d(in_channels=layers[1], out_channels=1, kernel_size=1),\n",
    "            WeightedConv2d(in_channels=layers[2], out_channels=1, kernel_size=1),\n",
    "            WeightedConv2d(in_channels=layers[3], out_channels=1, kernel_size=1),\n",
    "            WeightedConv2d(in_channels=layers[4], out_channels=1, kernel_size=1),\n",
    "            WeightedConv2d(in_channels=layers[5], out_channels=1, kernel_size=1),\n",
    "        ])\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(*[\n",
    "                PixelWiseNormalization(),\n",
    "                torch.nn.ConvTranspose2d(in_channels=layers[0], out_channels=layers[0], kernel_size=4, stride=1, padding=0),\n",
    "                torch.nn.LeakyReLU(0.2),\n",
    "                WeightedConv2d(in_channels=layers[0], out_channels=layers[0], kernel_size=3, padding=1),\n",
    "                torch.nn.LeakyReLU(0.2),\n",
    "                PixelWiseNormalization()\n",
    "            ]),\n",
    "            ConvBlock(layers[0], layers[1], apply_pixelnorm=True),\n",
    "            ConvBlock(layers[1], layers[2], apply_pixelnorm=True),\n",
    "            ConvBlock(layers[2], layers[3], apply_pixelnorm=True),\n",
    "            ConvBlock(layers[3], layers[4], apply_pixelnorm=True),\n",
    "            ConvBlock(layers[4], layers[5], apply_pixelnorm=True)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, surrogate_window, step, alpha):\n",
    "        x = torch.concatenate([surrogate_window[:, :, None, None], x], dim=1)\n",
    "\n",
    "        for i in range(step + 1):\n",
    "            # Don't upsample the first layer\n",
    "            x_upscaled = F.interpolate(x, scale_factor=2, mode='nearest') if i != 0 else x\n",
    "\n",
    "            x = self.layers[i](x_upscaled)\n",
    "\n",
    "        final_out = self.togray_layers[step](x)\n",
    "\n",
    "        # Fade-in except on step 0\n",
    "        if step != 0:\n",
    "            final_upscaled = self.togray_layers[step - 1](x_upscaled)\n",
    "            o = final_out * alpha + final_upscaled * (1 - alpha)\n",
    "            return torch.tanh(o)\n",
    "\n",
    "        return torch.tanh(final_out)\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.fromgray_layers = torch.nn.ModuleList([\n",
    "            WeightedConv2d(in_channels=1, out_channels=layers[0], kernel_size=1),\n",
    "            WeightedConv2d(in_channels=1, out_channels=layers[1], kernel_size=1),\n",
    "            WeightedConv2d(in_channels=1, out_channels=layers[2], kernel_size=1),\n",
    "            WeightedConv2d(in_channels=1, out_channels=layers[3], kernel_size=1),\n",
    "            WeightedConv2d(in_channels=1, out_channels=layers[4], kernel_size=1),\n",
    "            WeightedConv2d(in_channels=1, out_channels=layers[5], kernel_size=1)\n",
    "        ])\n",
    "        self.act = torch.nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            ConvBlock(layers[0], layers[1]),\n",
    "            ConvBlock(layers[1], layers[2]),\n",
    "            ConvBlock(layers[2], layers[3]),\n",
    "            ConvBlock(layers[3], layers[4]),\n",
    "            ConvBlock(layers[4], layers[5]),\n",
    "            torch.nn.Sequential(*[\n",
    "                MiniBatchStd(),\n",
    "                WeightedConv2d(in_channels=layers[5]+1, out_channels=layers[5], kernel_size=3, padding=1),\n",
    "                torch.nn.LeakyReLU(0.2),\n",
    "                WeightedConv2d(in_channels=layers[5], out_channels=layers[5], kernel_size=4, padding=0),\n",
    "                torch.nn.LeakyReLU(0.2),\n",
    "                torch.nn.Flatten(),\n",
    "                torch.nn.Linear(layers[5], out_features=1)\n",
    "            ])\n",
    "        ])\n",
    "\n",
    "    def forward(self, input, step, alpha):\n",
    "        x = self.fromgray_layers[len(self.fromgray_layers) - step - 1](input)\n",
    "        x = self.act(x)\n",
    "\n",
    "        for i in range(len(self.layers) - step - 1, len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "\n",
    "            # Don't pool for the last layer\n",
    "            x = F.avg_pool2d(x, kernel_size=2) if i != len(self.layers) - 1 else x\n",
    "\n",
    "            # Fade-in in first layer except for step 0\n",
    "            if i == len(self.layers) - step - 1 and step != 0:\n",
    "                x_hat = F.avg_pool2d(input, kernel_size=2)\n",
    "                x_hat = self.fromgray_layers[len(self.fromgray_layers) - step](x_hat)\n",
    "                x = x_hat * (1 - alpha) + x * alpha\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConditionalProGAN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 device,\n",
    "                 desired_resolution,\n",
    "                 G_lr,\n",
    "                 D_lr,\n",
    "                 n_critic,\n",
    "                 n_epochs,\n",
    "                 D_layers,\n",
    "                 G_layers):\n",
    "        super(ConditionalProGAN, self).__init__()\n",
    "        self.desired_resolution = desired_resolution\n",
    "        self.total_steps = 1 + math.log2(desired_resolution / 4)\n",
    "        if n_epochs % self.total_steps != 0:\n",
    "            raise Exception(\"Total number of epochs should be divisible by the total number of steps\")\n",
    "        \n",
    "        self.n_epochs = n_epochs\n",
    "        self.noise_vector_length = G_layers[0] - 17\n",
    "        self.device = device\n",
    "        self.D = Discriminator(D_layers).to(device)\n",
    "        self.G = Generator(G_layers).to(device)\n",
    "        self.n_critic = n_critic\n",
    "        self.G_optimizer = torch.optim.Adam(self.G.parameters(), betas=(0, 0.99), lr=G_lr, eps=1e-8)\n",
    "        self.D_optimizer = torch.optim.Adam(self.D.parameters(), betas=(0, 0.99), lr=D_lr, eps=1e-8)\n",
    "\n",
    "        self.G_scheduler = lr_scheduler.LinearLR(self.G_optimizer, start_factor=1, end_factor=.01, total_iters=n_epochs)\n",
    "        self.D_scheduler = lr_scheduler.LinearLR(self.D_optimizer, start_factor=1, end_factor=.01, total_iters=n_epochs)\n",
    "\n",
    "    def train_single_epoch(self, dataloader, current_epoch, gp_lambda, step, alpha, epochs_in_curr_step, dataset_length):\n",
    "        self.D.train()\n",
    "        self.G.train()\n",
    "\n",
    "        running_D_loss, running_G_loss = 0, 0\n",
    "        for data in tqdm(dataloader, desc=f\"Epoch {current_epoch + 1}, step {step}, alpha {round(alpha, 2)}: \", total=len(dataloader)):\n",
    "            mri_batch = data[\"mr\"].to(self.device)\n",
    "            coil_batch = data[\"coil\"].to(self.device)\n",
    "\n",
    "            noise_batch = torch.randn(mri_batch.shape[0], self.noise_vector_length, 1, 1, device=self.device)\n",
    "            fake = self.G(noise_batch, coil_batch, step, alpha)\n",
    "            real_input = torch.nn.functional.adaptive_avg_pool2d(mri_batch, (4 * 2 ** step, 4 * 2 ** step))\n",
    "            d_fake = self.D(fake.detach(), step, alpha)\n",
    "            d_real = self.D(real_input[:, None], step, alpha)\n",
    "\n",
    "            gp = self.compute_gradient_penalty(real_input[:, None], fake, step, alpha)\n",
    "            d_loss = (\n",
    "                    -(torch.mean(d_real) - torch.mean(d_fake))\n",
    "                    + gp_lambda * gp\n",
    "                    + (0.001 * torch.mean(d_real ** 2))\n",
    "            )\n",
    "\n",
    "            self.D_optimizer.zero_grad()\n",
    "            d_loss.backward()\n",
    "            self.D_optimizer.step()\n",
    "\n",
    "            g_fake = self.D(fake, step, alpha)\n",
    "            g_loss = -torch.mean(g_fake)\n",
    "\n",
    "            self.G_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            self.G_optimizer.step()\n",
    "  \n",
    "            alpha += mri_batch.shape[0] / ((epochs_in_curr_step*.5) * dataset_length)\n",
    "            alpha = min(alpha, 1.0)\n",
    "\n",
    "            running_D_loss += d_loss.cpu().item()\n",
    "            running_G_loss += g_loss.cpu().item()\n",
    "\n",
    "        self.G_scheduler.step()\n",
    "        self.D_scheduler.step()\n",
    "\n",
    "        return running_D_loss, running_G_loss, alpha\n",
    "\n",
    "    def evaluate(self, dataloader, step, alpha):\n",
    "        self.D.eval()\n",
    "        self.G.eval()\n",
    "\n",
    "        fake_to_return = []\n",
    "        real_to_return = []\n",
    "        all_nmse = []\n",
    "        all_ssim = []\n",
    "        for data in dataloader:\n",
    "            mr_batch = data[\"mr\"].to(self.device)\n",
    "            coil_batch = data[\"coil\"].to(self.device)\n",
    "\n",
    "            noise_batch = torch.randn(mr_batch.shape[0], self.noise_vector_length, 1, 1, device=self.device)\n",
    "            fake = self.G(noise_batch, coil_batch, step, alpha)\n",
    "            fake_upscaled = F.interpolate(fake, scale_factor=2**(self.total_steps - step - 1), mode='nearest')\n",
    "            nmse = normalized_mean_squared_error(fake_upscaled, mr_batch).detach().cpu().numpy().flatten()\n",
    "            \n",
    "            for i in range(fake_upscaled.shape[0]):\n",
    "                img1 = fake_upscaled[i].detach().cpu().numpy().squeeze()\n",
    "                img2 = mr_batch[i, None, :, :].detach().cpu().numpy().squeeze()\n",
    "                curr_ssim = ssim(img1, img2, win_size=11, data_range=2)\n",
    "                all_ssim.append(curr_ssim)\n",
    "            all_nmse.extend(nmse)\n",
    "            fake_to_return.extend(fake_upscaled.detach().cpu().numpy())\n",
    "            real_to_return.extend(mr_batch.detach().cpu().numpy())\n",
    "\n",
    "        return np.array(fake_to_return), np.array(real_to_return), np.array(all_nmse), np.array(all_ssim)\n",
    "\n",
    "    def compute_gradient_penalty(self, real, fake, step, alpha):\n",
    "        epsilon = torch.rand((real.shape[0], 1, 1, 1), device=self.device)\n",
    "        x_hat = (epsilon * real + (1-epsilon)*fake.detach()).requires_grad_(True)\n",
    "\n",
    "        score = self.D(x_hat, step, alpha)\n",
    "        gradient = torch.autograd.grad(\n",
    "            inputs=x_hat,\n",
    "            outputs=score,\n",
    "            grad_outputs=torch.ones_like(score),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        gradient = gradient.view(gradient.shape[0], -1)\n",
    "        gradient_norm = gradient.norm(2, dim=1)\n",
    "        gradient_penalty = torch.mean((gradient_norm-1)**2)\n",
    "        return gradient_penalty\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_alpha_linear(curr_epoch, epochs_per_step, quickness):\n",
    "        alpha = quickness * (curr_epoch % epochs_per_step) / epochs_per_step\n",
    "\n",
    "        return min(alpha, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_step_linear(n_epochs, total_steps, curr_epoch):\n",
    "        epochs_per_step = n_epochs // total_steps\n",
    "        step = int(curr_epoch / (epochs_per_step))\n",
    "\n",
    "        return min(step, int(total_steps - 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_step_root(n_epochs, n_steps, curr_epoch):\n",
    "        return math.floor(n_steps / math.sqrt(n_epochs) * math.sqrt(curr_epoch))\n",
    "\n",
    "    def _get_milestones(self, n_epochs, n_steps):\n",
    "        milestones = []\n",
    "        for i in range(1, int(n_steps)):\n",
    "            milestone = math.ceil(n_epochs * i ** 2 / n_steps ** 2)\n",
    "            milestones.append(milestone)\n",
    "\n",
    "        return milestones\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_alpha_root(n_epochs, n_steps, curr_epoch, curr_step, quickness=2):\n",
    "        # curr_step = _get_step_root(n_epochs, n_steps, curr_epoch)\n",
    "\n",
    "        start_step = math.ceil(n_epochs * curr_step ** 2 / n_steps ** 2)\n",
    "        end_step = math.ceil(n_epochs * (curr_step + 1) ** 2 / n_steps ** 2)\n",
    "\n",
    "        dx = (end_step - start_step) / quickness\n",
    "        dy = 1\n",
    "\n",
    "        alpha = dy / dx * (curr_epoch - start_step)\n",
    "\n",
    "        return min(alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplitter:\n",
    "    def __init__(self, dataset, train_fraction, val_fraction, test_fraction):\n",
    "        self.dataset = dataset\n",
    "        self.splits = self.dataset.splits\n",
    "        self.patterns = list(self.splits.keys())\n",
    "\n",
    "        self.train_subsets = {}\n",
    "        self.val_subsets = {}\n",
    "        self.test_subsets = {}\n",
    "        for p in self.patterns:\n",
    "            start_idx = self.splits[p][\"start\"]\n",
    "            end_idx = self.splits[p][\"end\"]\n",
    "            idxs = torch.arange(start_idx, end_idx + 1)\n",
    "\n",
    "            # No Breath holds in training data because there is so little training data\n",
    "            if not p.endswith(\"BH\"):\n",
    "                train_split = int(len(idxs) * train_fraction)\n",
    "                train_idxs = idxs[:train_split]\n",
    "\n",
    "                val_split = int(len(idxs) * (train_fraction + val_fraction))\n",
    "                val_idxs = idxs[train_split:val_split]\n",
    "\n",
    "                test_idxs = idxs[val_split:]\n",
    "\n",
    "                self.train_subsets[p] = Subset(dataset, train_idxs)\n",
    "                self.val_subsets[p] = Subset(dataset, val_idxs)\n",
    "                self.test_subsets[p] = Subset(dataset, test_idxs)\n",
    "            else:\n",
    "                val_split = int(len(idxs) * val_fraction/(val_fraction + test_fraction))\n",
    "                val_idxs = idxs[:val_split]\n",
    "\n",
    "                test_idxs = idxs[val_split:]\n",
    "                self.val_subsets[p] = Subset(dataset, val_idxs)\n",
    "                self.test_subsets[p] = Subset(dataset, test_idxs)\n",
    "\n",
    "        self.concatenated_train = ConcatDataset(self.train_subsets.values())\n",
    "\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return self.concatenated_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path, patient, coil_normalizer=(0, 1), heat_normalizer=(0, 1), us_normalizer=(0, 1)):\n",
    "        with open(os.path.join(root_path, patient, \"settings.json\")) as file:\n",
    "            self.settings = json.load(file)\n",
    "            self.TR = self.settings[\"MRI\"][\"TR\"]\n",
    "            mri_freq = 1/self.TR\n",
    "            surrogate_freq = 50\n",
    "            self.signals_between_mrs = int(surrogate_freq//mri_freq)\n",
    "\n",
    "        with open(os.path.join(root_path, patient, \"mr.pickle\"), 'rb') as file:\n",
    "            self.mr = pickle.load(file)[\"images\"]\n",
    "            self.mr = np.clip(self.mr, a_min=0, a_max=255).astype(np.uint8)\n",
    "            self.mr = cv2.addWeighted(self.mr, 1.7, np.zeros(self.mr.shape, self.mr.dtype), 0, 0)\n",
    "            self.mr = torch.from_numpy(self.mr).float()\n",
    "            self.mr = self.mr * 2 / 255 - 1\n",
    "            self.mr = self.mr[:, :128, 32:-32]\n",
    "\n",
    "        with open(os.path.join(root_path, patient, \"surrogates.pickle\"), 'rb') as file:\n",
    "            surrogates = pickle.load(file)\n",
    "            self.us = np.float32(surrogates[\"us\"])\n",
    "\n",
    "            self.heat = torch.tensor(np.float32(surrogates[\"heat\"]))\n",
    "            self.heat = (self.heat - heat_normalizer[0]) / heat_normalizer[1]\n",
    "\n",
    "            self.coil = torch.tensor(np.float32(surrogates[\"coil\"]))\n",
    "            self.coil = (self.coil - coil_normalizer[0]) / coil_normalizer[1]\n",
    "\n",
    "        with open(os.path.join(root_path, patient, \"us_wave_detrended.pickle\"), \"rb\") as file:\n",
    "            self.us_wave = pickle.load(file)\n",
    "            self.us_wave = torch.tensor(np.float32(self.us_wave))\n",
    "            self.us_wave = (self.us_wave - us_normalizer[0]) / us_normalizer[1]\n",
    "\n",
    "        with open(os.path.join(root_path, patient, \"mr2us_new.pickle\"), 'rb') as file:\n",
    "            self.mr2us = pickle.load(file)[\"mr2us\"]\n",
    "\n",
    "        with open(os.path.join(root_path, patient, \"mr_wave.pickle\"), 'rb') as file:\n",
    "            self.mr_wave = torch.Tensor(pickle.load(file)[\"mri_waveform\"])\n",
    "\n",
    "        with open(os.path.join(root_path, patient, \"splits.pickle\"), 'rb') as file:\n",
    "            self.splits = pickle.load(file)\n",
    "\n",
    "    def set_normalizers(self, heat, us, coil):\n",
    "        self.heat_normalizer = heat\n",
    "        self.us_normalizer = us\n",
    "        self.coil_normalizer = coil\n",
    "\n",
    "    def visualize(self):\n",
    "        for img in self.mr:\n",
    "            cv2.imshow(\"Frame\", (img.numpy() + 1)/2)\n",
    "            cv2.waitKey(30)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mr = self.mr[idx]\n",
    "        mr2us = self.mr2us[idx]\n",
    "        heat = self.heat[mr2us-self.signals_between_mrs+1:mr2us+1]\n",
    "        coil = self.coil[mr2us-self.signals_between_mrs+1:mr2us+1]\n",
    "        us_wave = self.us_wave[mr2us-self.signals_between_mrs+1:mr2us+1]\n",
    "        mr_wave = self.mr_wave[idx]\n",
    "\n",
    "        return {\"mr\": mr, \"heat\": heat, \"mr_wave\": mr_wave, \"us_wave\": us_wave, \"coil\": coil}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mr.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(train_dataset):\n",
    "    loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "    data = next(iter(loader))\n",
    "    \n",
    "    heat = data[\"heat\"].mean(), data[\"heat\"].std()\n",
    "    coil = data[\"coil\"].mean(), data[\"coil\"].std()\n",
    "    us = data[\"us_wave\"].mean(), data[\"us_wave\"].std()\n",
    "\n",
    "    return heat, coil, us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(cProGAN, val_patterns, val_loaders, step, alpha):\n",
    "    vids = []\n",
    "    ssim_res, nmse_res = {}, {}\n",
    "    n = 0\n",
    "    mean_ssim, mean_nmse = 0, 0\n",
    "    for pattern, val_loader in zip(val_patterns, val_loaders):\n",
    "        fake_imgs, real_imgs, nmse, ssim = cProGAN.evaluate(val_loader, step, alpha)\n",
    "        ssim_res[pattern] = ssim.mean()\n",
    "        nmse_res[pattern] = nmse.mean()\n",
    "        n += len(ssim)\n",
    "        mean_ssim += ssim.mean() * len(ssim)\n",
    "        mean_nmse += nmse.mean() * len(nmse)\n",
    "        vid = np.concatenate([fake_imgs, real_imgs[:, None, :, :]], axis=3)\n",
    "        vid = np.uint8((vid + 1) / 2 * 255).repeat(3, axis=1)\n",
    "        vids.append(wandb.Video(vid, fps=5, caption=pattern))\n",
    "\n",
    "    ssim_res[\"All\"] = mean_ssim / n\n",
    "    nmse_res[\"All\"] = mean_nmse / n\n",
    "\n",
    "    return vids, ssim_res, nmse_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(subject):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    config = dict(\n",
    "        batch_size=6,\n",
    "        n_epochs=60,\n",
    "        desired_resolution=128,\n",
    "        G_learning_rate=0.001,\n",
    "        D_learning_rate=0.001,\n",
    "        GP_lambda=10,\n",
    "        n_critic=1,\n",
    "        patient=subject,\n",
    "        surrogates=\"All\",\n",
    "        D_layers=[8, 16, 32, 64, 128, 256],\n",
    "        G_layers=[256, 128, 64, 32, 16, 8]\n",
    "    )\n",
    "\n",
    "    data_root = os.path.join(\"F:\", os.sep, \"Formatted_datasets\")\n",
    "    dataset = CustomDataset(data_root, config[\"patient\"])\n",
    "    splitter = DatasetSplitter(dataset, .8, .1, .1)\n",
    "    train_dataset = splitter.get_train_dataset()\n",
    "    heat_normalizer, coil_normalizer, us_normalizer = get_mean_std(train_dataset)\n",
    "\n",
    "    dataset = CustomDataset(data_root, config[\"patient\"], coil_normalizer, heat_normalizer, us_normalizer)\n",
    "    splitter = DatasetSplitter(dataset, .8, .1, .1)\n",
    "    train_dataset = splitter.get_train_dataset()\n",
    "\n",
    "    val_patterns = [\"Regular Breathing\", \"Shallow Breathing\", \"Deep Breathing\", \"Deep BH\", \"Half Exhale BH\", \"Full Exhale BH\"]\n",
    "    val_loaders = []\n",
    "    for pattern in val_patterns:\n",
    "        loader = DataLoader(splitter.val_subsets[pattern], batch_size=10, shuffle=False, pin_memory=True)\n",
    "        val_loaders.append(loader)\n",
    "\n",
    "    cProGAN = ConditionalProGAN(\n",
    "        device=device,\n",
    "        desired_resolution=config[\"desired_resolution\"],\n",
    "        G_lr=config[\"G_learning_rate\"],\n",
    "        D_lr=config[\"D_learning_rate\"],\n",
    "        n_critic=config[\"n_critic\"],\n",
    "        n_epochs=config[\"n_epochs\"],\n",
    "        D_layers=config[\"D_layers\"],\n",
    "        G_layers=config[\"G_layers\"],\n",
    "    )\n",
    "    \n",
    "    prog_epochs = [0, 0, 0, 10, 20, 30]\n",
    "    batch_sizes = [0, 0, 0, 8, 8, 4]\n",
    "    top_ssim = 0\n",
    "    best_epoch = 0\n",
    "    for step, n_epochs in enumerate(prog_epochs):\n",
    "        alpha = 0\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_sizes[step], shuffle=True, pin_memory=True) if n_epochs != 0 else None\n",
    "\n",
    "        for i in range(n_epochs):\n",
    "            start_time = time.time()\n",
    "            D_loss, G_loss, alpha = cProGAN.train_single_epoch(train_dataloader, sum(prog_epochs[:step])+i, config[\"GP_lambda\"], step, alpha, n_epochs, len(train_dataset))\n",
    "            end_time = time.time()\n",
    "            vids, ssim, nmse = eval(cProGAN, val_patterns, val_loaders, step, alpha)\n",
    "\n",
    "            if step == cProGAN.total_steps - 1 and alpha == 1 and ssim[\"All\"] > top_ssim:\n",
    "                top_ssim = ssim[\"All\"]\n",
    "                torch.save(cProGAN.G.state_dict(), f\"C:\\\\dev\\\\depth-tests\\\\GAN\\\\best_models\\\\{run.name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m subjects \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG4\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m subjects:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(subject)\u001b[0m\n\u001b[0;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m      6\u001b[0m     n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     G_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m data_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39msep, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormatted_datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatient\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m splitter \u001b[38;5;241m=\u001b[39m DatasetSplitter(dataset, \u001b[38;5;241m.8\u001b[39m, \u001b[38;5;241m.1\u001b[39m, \u001b[38;5;241m.1\u001b[39m)\n\u001b[0;32m     21\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39mget_train_dataset()\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[1;34m(self, root_path, patient, coil_normalizer, heat_normalizer, us_normalizer)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignals_between_mrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(surrogate_freq\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mmri_freq)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, patient, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmr.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr, a_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, a_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maddWeighted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr, \u001b[38;5;241m1.7\u001b[39m, np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "subjects = [\"D1\", \"D2\", \"D3\", \"E1\", \"E2\", \"E3\", \"F1\", \"F3\", \"F4\", \"G2\", \"G3\", \"G4\"]\n",
    "for s in subjects:\n",
    "    train(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
